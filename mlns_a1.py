# -*- coding: utf-8 -*-
"""MLNS_A1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iXUVP4Wm6BiQY7jBkrpx2jBnpKYE78IW
"""

!pip3 install torch torchvision

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt

from tqdm import tqdm

data_files = ['data0.npy', 'data1.npy', 'data2.npy']
label_files = ['lab0.npy', 'lab1.npy', 'lab2.npy']

data = np.load('data0.npy')
data = np.append(data, np.load('data1.npy'), axis=0)
data = np.append(data, np.load('data2.npy'), axis=0)
data = np.array([[i] for i in data])
data = torch.from_numpy(data.astype(np.float32))

labels = np.load('lab0.npy')
labels = np.append(labels, np.load('lab1.npy'), axis=0)
labels = np.append(labels, np.load('lab2.npy'), axis=0)
labels = torch.from_numpy(labels.astype(np.long))
    
train_data = data[:27000]
train_labels = labels[:27000]

test_data = data[27000:]
test_labels = labels[27000:]

print(train_data.shape, train_labels.shape)
i = 1
plt.imshow(test_data[i][0])

BATCH_SIZE = 32

trainset = torch.utils.data.TensorDataset(train_data,train_labels)
testset = torch.utils.data.TensorDataset(test_data,test_labels)

trainset, valset = torch.utils.data.random_split(trainset, [int(0.8 * len(trainset)), int(0.2 * len(trainset))])

trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

import matplotlib.pyplot as plt
import numpy as np

## functions to show an image
def imshow(img):
    #img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

## get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()
## show images
imshow(torchvision.utils.make_grid(images))

for images, labels in trainloader:
    print("Image batch dimensions:", images.shape)
    print("Image label dimensions:", labels.shape)
    break

class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.d1 = nn.Linear(40 * 168 * 1, 2000)
        self.d2 = nn.Linear(2000, 1000)
        self.d3 = nn.Linear(1000, 500)
        self.d4 = nn.Linear(500, 37)

    def forward(self, x):
        x = x.flatten(start_dim = 1)
        x = self.d1(x)
        x = F.relu(x)
        x = self.d2(x)
        x = F.relu(x)
        x = self.d3(x)
        x = F.relu(x)
        logits = self.d4(x)
        out = F.softmax(logits, dim=1)
        
        return out

## test the model with 1 batch
model = MyModel()
for images, labels in trainloader:
    print("batch size:", images.shape)
    out = model(images)
    print(out.shape)
    break

learning_rate = 0.00001
num_epochs = 100

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = MyModel()
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

## compute accuracy
def get_accuracy(logit, target, batch_size):
    ''' Obtain accuracy for training round '''
    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()
    accuracy = 100.0 * corrects/batch_size
    return accuracy.item()

train_loss = list()
val_loss = list()
train_acc = list()
val_acc = list()

for epoch in tqdm(range(num_epochs)):
    total_train_loss = 0
    total_val_loss = 0

    total_train_acc = 0.0
    total_val_acc = 0.0

    model = model.train()

    ## training step
    for i, (images, labels) in enumerate(trainloader):
        
        images = images.to(device)
        labels = labels.to(device)

        ## forward + backprop + loss
        pred = model(images)
        loss = criterion(pred, labels)
        optimizer.zero_grad()
        loss.backward()

        ## update model params
        optimizer.step()

        total_train_loss += loss.detach().item()
        total_train_acc += get_accuracy(pred, labels, BATCH_SIZE)
    
    total_train_loss = total_train_loss/i
    total_train_acc = total_train_acc/i
    train_loss.append(total_train_loss)
    train_acc.append(total_train_acc)

    model.eval()

    ## validation step
    for i, (images, labels) in enumerate(valloader):
        
        images = images.to(device)
        labels = labels.to(device)

        ## forward + backprop + loss
        pred = model(images)
        loss = criterion(pred, labels)

        total_val_loss += loss.detach().item()
        total_val_acc += get_accuracy(pred, labels, BATCH_SIZE)

    total_val_loss = total_val_loss/i
    total_val_acc = total_val_acc/i
    val_loss.append(total_val_loss)
    val_acc.append(total_val_acc)

    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Val Loss: %.4f | Val Accuracy: %.2f' %(epoch, total_train_loss, total_train_acc, total_val_loss, total_val_acc ))

test_acc = 0.0
for i, (images, labels) in enumerate(testloader, 0):
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)
        
print('Test Accuracy: %.2f'%( test_acc/i))

fig=plt.figure(figsize=(20, 10))
plt.plot(np.arange(1, num_epochs+1), train_loss, label="Train loss")
plt.plot(np.arange(1, num_epochs+1), val_loss, label="Validation loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title("Loss Plots")
plt.legend(loc='upper right')
plt.show()
# plt.savefig('loss.png')

fig=plt.figure(figsize=(20, 10))
plt.plot(np.arange(1, num_epochs+1), train_acc, label="Train Accuracy")
plt.plot(np.arange(1, num_epochs+1), val_acc, label="Validation Accuracy")
plt.xlabel('Accuracy (%)')
plt.ylabel('Epochs')
plt.title("Accuracy Plots")
plt.legend(loc='upper right')
plt.show()

torch.save(model, './model.zip')

